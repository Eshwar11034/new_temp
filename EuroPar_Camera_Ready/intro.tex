In modern engineering, the demand for efficient optimization techniques is critical across disciplines such as structural engineering, material sciences, and molecular dynamics. Nonlinear programming (NLP) has emerged as a fundamental tool for addressing complex design challenges, as these problems involve intricate, nonlinear relationships that govern system performance and reliability. In structural engineering, NLP facilitates the optimization of large-scale structures, while in material sciences, it enables the development of novel materials with tailored properties. Similarly, molecular dynamics relies on nonlinear equations to model particle interactions, requiring advanced optimization techniques to accurately capture complex behaviors. As the complexity and dimensionality of design spaces continue to expand, advanced computational methods are essential for achieving efficient and scalable solutions.

\noindent
\textbf{SLSQP:} Sequential Least Squares Quadratic Programming \cite{SLSQP} is a well established algorithm for solving NLP problems involving constrained, smoo-th, and differentiable functions. At each iteration, SLSQP constructs a quadratic approximation of the nonlinear objective function while employing a linearization of the constraints, resulting in a quadratic programming (QP) subproblem that determines the search direction for updating decision variables. Despite its effectiveness, the sequential execution of core linear algebra operations poses computational challenges, particularly in high-dimensional optimization problems. As problem dimensionality increases, these sequential computations introduce performance bottlenecks, necessitating the exploration of more efficient and scalable approaches\cite{gill2015performance}.

% Addressing these computational challenges is crucial not only for enhancing algorithmic efficiency but also for facilitating advancements in domains where optimization plays a pivotal role. While optimized numerical libraries with parallel implementations of QR factorization(a fundamental operation in each SLSQP iteration) are readily available, integrating these improvements into open-source frameworks such as NLOPT\cite{NLopt} remains a significant challenge. Despite the promising potential of parallel computing, effectively harnessing these resources typically requires specialized expertise, a requirement that many users find challenging. This dependency on expert knowledge has created a significant barrier that limits the broader adoption of parallel techniques. As a result, there remains a notable gap in the integration of advanced, efficient parallel computing methods within widely used optimization libraries, thereby curtailing their accessibility and overall impact on computational performance.

\noindent
\textbf{QR Factorization:} Enhancing algorithm efficiency is key for progress in optimi-zation driven fields. The QR Factorization is a mathematical technique used to decompose a matrix \(A\) into an orthogonal matrix \(Q\) and an upper triangular matrix \(R\). Methods like Householder transformations achieve this by iteratively applying a sequence of reflection matrices \(H_k\) to \(A\). Each \(H_k\) is constructed from the current state of the \(k\)-th column. The \emph{critical intermediate results} of this process are the components defining these Householder reflectors. The final \(R\) matrix resides in the upper triangle, while \(Q\) is implicitly represented as the product of the \(H_k\) transformations (\(Q = H_1 H_2 \dots H_m\)). In algorithms like SLSQP, which iteratively solve systems of equations or least-squares problems arising from Quadratic Programming (QP) subproblems, these stored intermediate results are paramount. They allow for the efficient application of \(Q\) or \(Q^T\) to various matrices and vectors without explicitly forming the (potentially dense) matrix \(Q\). This repeated application is fundamental to updating solutions and Lagrange multipliers within SLSQP. QR Factorization is a critical sub-routine of SLSQP that is invoked multiple times, making the management and parallel computation of these intermediate results crucial for overall algorithmic performance.

This study presents parallel techniques for QR factorization that harness the advantages of concurrent task execution. By decomposing QR factorization into smaller, independent tasks suitable for parallel processing, an asynchronous Directed Acyclic Task Graph (DATG) scheduling mechanism is employed to optimize execution while preserving task dependencies.

Empirical evaluations demonstrate substantial performance gains in solving large-scale NLP problems using the SLSQP algorithm. The results underscore the transformative impact of parallel computing techniques on QR factorization, reinforcing the necessity for high-performance numerical methods within open-source optimization frameworks.

% This research aims to enhance computational efficiency across disciplines such as structural engineering, material science, and molecular dynamics, facilitating the development of more effective solutions for complex optimization problems and driving innovation in these critical domains.
% Sequential Least Squares Quadratic Programming (SLSQP)\cite{SLSQP} is an iterative algorithm to solve nonlinear programming (NLP) problems. At each iteration, SLSQP constructs a quadratic approximation of the non-linear objective function while simultaneously linearizing the constraint functions. This approach results in a quadratic programming (QP) subproblem whose solution informs the optimal search direction, allowing decision variables to be updated iteratively. The iteration process continues until the specified convergence criteria are met.

% Despite SLSQP's robustness in handling constrained, smooth, and differentiable functions, its computational efficiency can be hampered by the sequential execution of core linear algebra operations. This limitation becomes particularly pronounced in high-dimensional optimization problems, where sequential processing can result in performance bottlenecks\cite{zahery2017csolnp}\cite{liu2022survey}\cite{gill2015performance}.

% Our research focuses on the QR decomposition kernel, a fundamental component in each iteration of SLSQP. Although optimized numerical libraries provide efficient parallel implementations of QR factorization, their integration into open-source optimization frameworks such as NLOPT\cite{NLopt} remains a challenge. This process often requires specialized expertise in the application domain and the underlying hardware architecture, which poses significant barriers to adoption. As a result, there has been little to no active effort to incorporate efficient parallel QR factorization techniques into widely used open-source libraries like NLOPT, leaving a critical gap in computational optimization research.

% In this work, we propose a parallel approach to improve the efficiency of QR factorization by using parallel task execution. By decomposing the QR factorization into smaller independent tasks that can be processed in parallel, we utilize asynchronous Directed Acyclic Graph (DAG) scheduling to optimize task execution based on dependencies. This dynamic restructuring of linear algebra operations significantly reduces the time required for QR factorization during optimization. Our optimized task execution framework is seamlessly integrated into the SLSQP implementation of the NLOPT library. Through empirical evaluations, we demonstrate substantial performance improvements in solving large-scale nonlinear programming problems, highlighting the effectiveness of parallel computing techniques in enhancing nonlinear optimization efficiency. This research contributes to the broader initiative of integrating high-performance numerical methods into open source optimization frameworks, thereby expanding the applicability and accessibility of SLSQP in domains such as machine learning, engineering design, and financial modeling.
%\vspace{3pt} % Optional spacing for better readability


\noindent \textbf{Our Contributions:} The key contributions of this work are as follows.
\begin{itemize}
	\item  Developed a dynamic algorithm that schedules QR factorization into smaller tasks using asynchronous DATG scheduling\hyperref[alg:thdwork]{Alg. 5}.
	\item Integrated the optimized parallel QR factorization method into the SLSQP implementation of the open-source NLOPT library. 
	\item Comprehensive evaluations demonstrated a 10x improvement of the parallel QR technique over the sequential QR version of the SLSQP algorithm. %\todo{Please add the improvements in the throughput here.}
\end{itemize}
